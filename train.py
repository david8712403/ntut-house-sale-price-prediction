# -*- coding: utf-8 -*-
"""ntut-2021-autumn-regression-110368014.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OO2XR5JglGU7mxu7IxPqOG2Bd24scj5_
"""

# Commented out IPython magic to ensure Python compatibility.
# For nn training
import tensorflow 
from tensorflow import keras
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import Adam, SGD
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras import callbacks

# For data preprocess
from datetime import date, datetime
import numpy as np
import csv
import os

import pandas as pd

# For plotting
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

import matplotlib.pyplot as plt
from mlxtend.plotting import scatterplotmatrix

# %matplotlib inline
from tensorflow.keras import callbacks

root_dir = "/usr/src/dataset/ntut-ml-regression-2021"
train_dir = root_dir + "/train-v3.csv"
valid_dir = root_dir + "/valid-v3.csv"
test_dir = root_dir + "/test-v3.csv"

"""## 資料預處理
嘗試將train valid 兩組資料合併，處理完之後在打散
"""

# load dataset to dataframe
train_df = pd.read_csv(train_dir)
valid_df = pd.read_csv(valid_dir)
test_df = pd.read_csv(test_dir)
train_df

merge_df = train_df.append(valid_df, ignore_index=True)
merge_df

# train_df['date'] = train_df['sale_yr'].astype(str) + "/" + train_df['sale_month'].astype(str) + "/" +  train_df['sale_day'].astype(str)
# train_df['date'] = pd.to_datetime(train_df['date'])
# train_df['date'] = train_df.date.values.astype(np.int64) // 10 ** 9
# train_df

cols = [
    "id",
    "sale_yr", 
    "sale_month",
    "sale_day",
    "bedrooms",
    "bathrooms",
    "sqft_living",
    "sqft_lot",
    "floors",
    "waterfront",
    "view",
    "condition",
    "grade",
    "sqft_above",
    "sqft_basement",
    "yr_built",
    "yr_renovated",
    "zipcode",
    "lat",
    "long",
    "sqft_living15",
    "sqft_lot15",
    "price"
]
# scatterplotmatrix(merge_df[cols].values.astype(float), figsize=(50,50), names=cols, alpha=0.5)
# plt.tight_layout()
# plt.show()

print(merge_df.corr().sort_values(by=['price'])['price'])

# remove extreme rows
merge_df = merge_df[merge_df['bedrooms'] < 30]
# merge_df = merge_df[merge_df['sqft_living'] < 12000]
# merge_df = merge_df[merge_df['sqft_lot15'] < 800000]
merge_df = merge_df[merge_df['bathrooms'] != 0]
merge_df = merge_df[merge_df['bedrooms'] != 0]

# Replace 'yr_built' with 'yr_renovated' where is not equal 0
merge_df.loc[merge_df['yr_renovated'] != 0, 'yr_built'] = merge_df['yr_renovated']
test_df.loc[test_df['yr_renovated'] != 0, 'yr_built'] = test_df['yr_renovated']

# valid_df.corr().sort_values(by=['price'])['price']
print(merge_df.corr().sort_values(by=['price'])['price'])

drop_cols = ['id', 'sale_month', 'sale_day', 'zipcode', 'condition', 'yr_renovated']
input_dim = len(cols) - (len(drop_cols) + 1)
merge_df = merge_df.drop(drop_cols, axis=1)

"""## Split train data"""

from sklearn.model_selection import train_test_split
train, valid = train_test_split(merge_df, test_size=0.2, random_state=103)
# train data
x_train = train.drop(['price'], axis=1)
y_train = train['price'].values

# valid data
x_valid = valid.drop(['price'], axis=1)
y_valid = valid['price'].values

# test data
x_test = test_df.drop(drop_cols, axis=1)
train_df

mean = x_train.mean()
std = x_train.std()
print(mean)
print(std)
x_train = (x_train-mean) / std
x_valid = (x_valid-mean) / std
x_test = (x_test-mean) / std

"""## Training model"""

init_weight = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=57)

model = Sequential()
model.add(Dense(64, input_dim=input_dim, kernel_initializer=init_weight, activation='relu'))
# model.add(Dense(64, kernel_initializer=init_weight, activation='relu'))
model.add(Dense(64, kernel_initializer=init_weight, activation='relu'))
model.add(Dense(64, kernel_initializer=init_weight, activation='relu'))
# model.add(Dense(64, activation='relu'))
model.add(Dense(64, kernel_initializer=init_weight, activation='relu'))
model.add(Dense(32, kernel_initializer=init_weight, activation='relu'))
model.add(Dense(32, kernel_initializer=init_weight, activation='relu'))
model.add(Dense(1))

opt = Adam(learning_rate=0.02)
# opt = SGD( decay=1e-8, momentum=0.9)
model.compile(loss='MAE', optimizer=opt)
model.summary()

es = callbacks.EarlyStopping(patience=50, monitor='val_loss', mode='auto')
check_point = callbacks.ModelCheckpoint(
    'model.h5',
    monitor='val_loss',
    verbose=3,
    save_best_only=True,
    save_weight_only=True,
    mode='auto',
    period=1
)
my_callbacks = [es, check_point]

batch_size = 32
epochs = 1000
model.fit(
    x_train, y_train,
    batch_size=batch_size,
    epochs=epochs,
    verbose=1,
    validation_data=(x_valid, y_valid),
    callbacks=my_callbacks
)

"""## Result"""

losses = pd.DataFrame(model.history.history)
losses.plot()

"""## Predict"""

model = keras.models.load_model('model.h5')
predict_price = model.predict(x_test)
predict_price

with open(f"predict_result_{datetime.now()}.csv", "w") as f:
    f.write('id,price\n')
    for i in range(len(predict_price)):
        f.write(f"{i+1},{float(predict_price[i])}\n")